{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a04b218-c619-4634-9380-14993ef75491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import random\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import time\n",
    "from transformers import AutoModel, AutoConfig, get_linear_schedule_with_warmup, AutoTokenizer\n",
    "from sklearn.metrics import log_loss\n",
    "import torch.utils.checkpoint\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "import sys\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46ee41e-2fbf-42a6-b824-1ec1092f2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = '001'\n",
    "TRAIN_PATH = '../../data/train_folds.csv'\n",
    "TEST_PATH = '../../data/test.csv'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8061ce26-e049-45e0-8c7d-28566799c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_len = 512\n",
    "\n",
    "deberta_v3_large_MODEL_PATH = './tokenizer'\n",
    "deberta_v3_large_tokenizer = AutoTokenizer.from_pretrained(deberta_v3_large_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07777b6b-3916-4ec2-a1d2-dd5d4a925c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e8e210f-36b1-426d-a1a9-4d85b44df659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data_dict, max_len):\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_len=max_len\n",
    "        self.texts = data_dict['text'].values\n",
    "        self.labels = data_dict['label'].values\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        SEP = self.tokenizer.sep_token\n",
    "        text = self.texts[index]\n",
    "        text = text.replace('[SEP]', SEP)\n",
    "        tokenized = self.tokenizer(text=self.texts[index],\n",
    "                                   add_special_tokens=True,\n",
    "                                   max_length=self.max_len,\n",
    "                                   padding='max_length',\n",
    "                                   truncation=True,\n",
    "                                   return_tensors='pt')\n",
    "        target = np.zeros(3, dtype=np.int64)\n",
    "        target[self.labels[index]] = 1\n",
    "        return tokenized['input_ids'].squeeze(), tokenized['attention_mask'].squeeze(), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5712c65f-6b24-43f2-b0ab-ff787ed2e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9) #\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class FeedbackModel(nn.Module):\n",
    "\n",
    "    def __init__(self,model_name=None, config_path=None, pretrained=True, num_labels=3):\n",
    "        super(FeedbackModel,self).__init__()\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(model_name, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        self.pooler = MeanPooling()\n",
    "        self.output = nn.Linear(self.config.hidden_size,num_labels)\n",
    "        \n",
    "        self.model.embeddings.requires_grad_(False)\n",
    "        self.model.encoder.layer[:2].requires_grad_(False)\n",
    "#         self.model.gradient_checkpointing_enable()\n",
    "        if 'deberta-v2-xxlarge' in model_name:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:24].requires_grad_(False) # 冻结24/48\n",
    "        if 'deberta-v2-xlarge' in model_name:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:12].requires_grad_(False) # 冻结12/24\n",
    "        if 'funnel-transformer-xlarge' in model_name:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.blocks[:1].requires_grad_(False) # 冻结1/3\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        if 'gpt' in self.model.name_or_path:\n",
    "            emb = self.model(input_ids)[0]\n",
    "        else:\n",
    "            emb = self.model(input_ids,attention_mask)[0]\n",
    "\n",
    "        emb = self.pooler(emb, attention_mask)\n",
    "        preds1 = self.output(self.dropout1(emb))\n",
    "        preds2 = self.output(self.dropout2(emb))\n",
    "        preds3 = self.output(self.dropout3(emb))\n",
    "        preds4 = self.output(self.dropout4(emb))\n",
    "        preds5 = self.output(self.dropout5(emb))\n",
    "\n",
    "        preds = (preds1 + preds2 + preds3 + preds4 + preds5) / 5\n",
    "#         preds = torch.softmax(preds, dim=-1)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa3c7d8-1eb8-46c3-bb42-19cc3fb0cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_unidecode import unidecode\n",
    "from typing import Dict, List, Tuple\n",
    "import codecs\n",
    "\n",
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
    "    text = (\n",
    "        text.encode(\"raw_unicode_escape\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "    )\n",
    "    text = unidecode(text)\n",
    "    return text\n",
    "\n",
    "def add_separators(context):\n",
    "    if len(context) > 1:\n",
    "        context = '[SEP]' + context\n",
    "    return context\n",
    "\n",
    "def get_essay(essay_id, is_train=True):\n",
    "    parent_path = INPUT_DIR + 'train' if is_train else INPUT_DIR + 'test'\n",
    "    essay_path = os.path.join(parent_path, f\"{essay_id}.txt\")\n",
    "    essay_text = open(essay_path, 'r').read()\n",
    "    return essay_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce6ee1ee-73ba-4f9c-b73c-5db6f6f3923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_PATH)\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "INPUT_DIR = '../../data/'\n",
    "test['essay_text']  = test['essay_id'].apply(lambda x: get_essay(x, is_train=False))\n",
    "test['discourse_text'] = test['discourse_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "test['essay_text'] = test['essay_text'].apply(lambda x : resolve_encodings_and_normalize(x))\n",
    "test['text'] = test['discourse_type'] + ' ' + test['discourse_text'] + '[SEP]' + test['essay_text']\n",
    "fold_array = train['fold'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450066aa-10d4-4f78-baa6-3d69b43f4693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def softmax(z):\n",
    "    assert len(z.shape) == 2\n",
    "    s = np.max(z, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(z - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis] # dito\n",
    "    return e_x / div\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    y_pred = softmax(y_pred)\n",
    "    score = log_loss(y_true, y_pred)\n",
    "    return round(score, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2dc6e08-4655-4ebc-9bb1-bb36e1191ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.83198725e-02 9.29174185e-01 2.25058720e-02]\n",
      " [6.14187717e-02 7.20364153e-01 2.18217090e-01]\n",
      " [6.26790002e-02 8.67462754e-01 6.98581859e-02]\n",
      " [7.12173358e-02 8.66039574e-01 6.27431720e-02]\n",
      " [1.81827784e-01 8.05118203e-01 1.30539890e-02]\n",
      " [4.50502396e-01 5.47653735e-01 1.84386561e-03]\n",
      " [6.07365966e-01 3.91420871e-01 1.21316651e-03]\n",
      " [6.23846769e-01 3.75299752e-01 8.53457663e-04]\n",
      " [4.40039128e-01 5.54079533e-01 5.88134862e-03]\n",
      " [2.50553578e-01 7.44796872e-01 4.64951666e-03]]\n",
      "EVAL: [0/230] Loss: 0.3821(0.3821) \n",
      "[[8.67516920e-03 7.08160460e-01 2.83164412e-01]\n",
      " [4.35182918e-03 3.47264975e-01 6.48383200e-01]\n",
      " [4.48539900e-03 3.34119648e-01 6.61394894e-01]\n",
      " [3.27101024e-03 2.62397826e-01 7.34331191e-01]\n",
      " [2.99349725e-02 6.28071070e-01 3.41993868e-01]\n",
      " [6.95945811e-04 9.02013928e-02 9.09102619e-01]\n",
      " [4.26788087e-04 4.77327220e-02 9.51840460e-01]\n",
      " [1.41075263e-02 4.66786027e-01 5.19106448e-01]\n",
      " [1.77971460e-02 5.73909402e-01 4.08293426e-01]\n",
      " [9.19058162e-04 8.61116350e-02 9.12969351e-01]]\n",
      "EVAL: [50/230] Loss: 0.7897(0.5731) \n",
      "[[0.0430865  0.93981379 0.01709968]\n",
      " [0.33401555 0.66126764 0.00471671]\n",
      " [0.06396719 0.91849548 0.01753728]\n",
      " [0.40051955 0.58892393 0.01055648]\n",
      " [0.06568585 0.91833395 0.0159801 ]\n",
      " [0.05272653 0.90549189 0.04178165]\n",
      " [0.87283432 0.12492705 0.00223868]\n",
      " [0.6381923  0.35680899 0.00499876]\n",
      " [0.28412318 0.64857781 0.06729908]\n",
      " [0.0122328  0.64655155 0.3412157 ]]\n",
      "EVAL: [100/230] Loss: 0.6823(0.5878) \n",
      "[[0.24330264 0.75373954 0.00295773]\n",
      " [0.23990938 0.75792038 0.00217022]\n",
      " [0.26481533 0.73224193 0.00294284]\n",
      " [0.3736766  0.62260973 0.00371364]\n",
      " [0.62155706 0.37691113 0.00153181]\n",
      " [0.41504163 0.58374029 0.00121803]\n",
      " [0.40845078 0.58749717 0.00405204]\n",
      " [0.25314948 0.73927957 0.00757102]\n",
      " [0.1506737  0.84627724 0.00304901]\n",
      " [0.40204701 0.59694034 0.00101259]]\n",
      "EVAL: [150/230] Loss: 0.8091(0.6255) \n",
      "[[0.00423601 0.33961031 0.65615362]\n",
      " [0.03054364 0.36565742 0.60379887]\n",
      " [0.00504702 0.1186301  0.87632293]\n",
      " [0.13664588 0.66737056 0.19598357]\n",
      " [0.03566176 0.67528439 0.28905392]\n",
      " [0.15015541 0.73108697 0.11875764]\n",
      " [0.00387269 0.13902578 0.85710156]\n",
      " [0.00577103 0.10970833 0.88452065]\n",
      " [0.00768548 0.22765183 0.76466268]\n",
      " [0.01922033 0.27951086 0.70126879]]\n",
      "EVAL: [200/230] Loss: 0.9313(0.6278) \n",
      "[[4.06793645e-03 2.67866373e-01 7.28065729e-01]\n",
      " [3.42196552e-04 3.62421535e-02 9.63415623e-01]\n",
      " [6.81467413e-04 8.92144218e-02 9.10104096e-01]\n",
      " [3.72193637e-04 4.02218886e-02 9.59405959e-01]\n",
      " [4.77575250e-02 7.50155389e-01 2.02087149e-01]\n",
      " [2.39722943e-03 2.44773671e-01 7.52829075e-01]\n",
      " [1.79660004e-02 5.83689928e-01 3.98344040e-01]\n",
      " [5.19939652e-03 3.75409544e-01 6.19391084e-01]\n",
      " [1.44498628e-02 5.34799278e-01 4.50750858e-01]\n",
      " [1.72147993e-03 1.82044193e-01 8.16234291e-01]]\n",
      "EVAL: [229/230] Loss: 0.3688(0.6172) \n",
      "[[0.01019953 0.28284341 0.70695704]\n",
      " [0.10101945 0.73592877 0.16305175]\n",
      " [0.00398743 0.13344087 0.86257172]\n",
      " [0.39744037 0.58623236 0.01632728]\n",
      " [0.01910966 0.67355174 0.30733863]\n",
      " [0.04329655 0.8400529  0.11665053]\n",
      " [0.11502733 0.80356485 0.08140786]\n",
      " [0.08616897 0.80538344 0.1084476 ]\n",
      " [0.11565576 0.79360276 0.09074155]\n",
      " [0.07638799 0.73853624 0.18507572]]\n",
      "EVAL: [0/230] Loss: 0.5464(0.5464) \n",
      "[[0.26268229 0.72505653 0.01226119]\n",
      " [0.11865081 0.82893914 0.05241   ]\n",
      " [0.23475504 0.72521991 0.04002504]\n",
      " [0.31298605 0.673567   0.01344698]\n",
      " [0.16673467 0.80879033 0.02447501]\n",
      " [0.23659611 0.74637085 0.01703307]\n",
      " [0.26612267 0.71886665 0.01501073]\n",
      " [0.11207087 0.80453968 0.08338946]\n",
      " [0.29166064 0.70195013 0.00638921]\n",
      " [0.56500489 0.42889911 0.00609606]]\n",
      "EVAL: [50/230] Loss: 0.4763(0.6552) \n",
      "[[0.23824318 0.70234305 0.0594138 ]\n",
      " [0.09099744 0.85538411 0.05361848]\n",
      " [0.07180643 0.79601002 0.13218364]\n",
      " [0.07991702 0.79256248 0.12752043]\n",
      " [0.3961094  0.59302992 0.01086065]\n",
      " [0.10464316 0.86416215 0.03119463]\n",
      " [0.42320374 0.56406569 0.0127306 ]\n",
      " [0.08701265 0.86064953 0.05233784]\n",
      " [0.19452183 0.7164101  0.08906808]\n",
      " [0.1047179  0.82693011 0.06835208]]\n",
      "EVAL: [100/230] Loss: 0.6948(0.6434) \n",
      "[[0.29852852 0.67424786 0.02722364]\n",
      " [0.09343562 0.77266645 0.13389798]\n",
      " [0.03819859 0.59630966 0.36549175]\n",
      " [0.1722773  0.79474741 0.03297527]\n",
      " [0.83256114 0.15386215 0.01357671]\n",
      " [0.18331477 0.78856307 0.02812214]\n",
      " [0.37335637 0.5942747  0.0323689 ]\n",
      " [0.19558407 0.75981468 0.0446012 ]\n",
      " [0.45364812 0.53217518 0.01417675]\n",
      " [0.16373375 0.79144472 0.04482147]]\n",
      "EVAL: [150/230] Loss: 0.7145(0.6503) \n",
      "[[0.72547674 0.2716085  0.00291476]\n",
      " [0.56825846 0.40307727 0.02866429]\n",
      " [0.67027146 0.3271074  0.00262116]\n",
      " [0.44368902 0.54015952 0.01615146]\n",
      " [0.81502092 0.18026167 0.00471743]\n",
      " [0.24933505 0.68821001 0.06245497]\n",
      " [0.53629792 0.45762551 0.00607663]\n",
      " [0.22509772 0.74090147 0.03400079]\n",
      " [0.10439332 0.81928474 0.07632195]\n",
      " [0.22268958 0.74720478 0.03010566]]\n",
      "EVAL: [200/230] Loss: 0.7804(0.6590) \n",
      "[[0.04158122 0.69614089 0.2622779 ]\n",
      " [0.46868509 0.52424139 0.00707356]\n",
      " [0.0576139  0.83949333 0.10289276]\n",
      " [0.0573416  0.78330797 0.1593504 ]\n",
      " [0.17541403 0.78535086 0.0392351 ]\n",
      " [0.06681586 0.82011628 0.11306782]\n",
      " [0.07603135 0.52648073 0.39748797]\n",
      " [0.13109449 0.82600796 0.04289758]\n",
      " [0.06560048 0.65321732 0.28118229]\n",
      " [0.20622535 0.76790899 0.02586559]]\n",
      "EVAL: [229/230] Loss: 0.7600(0.6551) \n",
      "[[1.08306959e-01 8.87570500e-01 4.12254455e-03]\n",
      " [1.29473105e-01 8.60657036e-01 9.86986235e-03]\n",
      " [1.18849159e-03 1.09231621e-01 8.89579952e-01]\n",
      " [1.63646636e-03 2.22935215e-01 7.75428295e-01]\n",
      " [1.38332853e-02 3.25490892e-01 6.60675883e-01]\n",
      " [2.09213118e-03 1.97936967e-01 7.99970865e-01]\n",
      " [9.91250388e-03 3.74004751e-01 6.16082728e-01]\n",
      " [8.59057822e-04 7.74223655e-02 9.21718597e-01]\n",
      " [2.72129895e-03 1.72571868e-01 8.24706852e-01]\n",
      " [8.26365722e-04 7.21839219e-02 9.26989734e-01]]\n",
      "EVAL: [0/230] Loss: 0.4151(0.4151) \n",
      "[[0.09414236 0.79409105 0.11176655]\n",
      " [0.00924145 0.38597313 0.60478538]\n",
      " [0.00724504 0.31069782 0.68205708]\n",
      " [0.00364182 0.06832108 0.92803711]\n",
      " [0.00256556 0.07660623 0.92082822]\n",
      " [0.01632264 0.50383401 0.47984332]\n",
      " [0.04956763 0.943811   0.00662137]\n",
      " [0.08187097 0.89707565 0.02105343]\n",
      " [0.09254783 0.89837974 0.00907251]\n",
      " [0.17933074 0.81555504 0.00511424]]\n",
      "EVAL: [50/230] Loss: 0.7021(0.6129) \n",
      "[[0.04674316 0.9122892  0.04096765]\n",
      " [0.11453219 0.87160283 0.01386493]\n",
      " [0.22631417 0.76799011 0.00569569]\n",
      " [0.08480345 0.89279705 0.02239949]\n",
      " [0.15434435 0.83675385 0.00890176]\n",
      " [0.40510562 0.59066164 0.00423271]\n",
      " [0.07095882 0.89236373 0.03667747]\n",
      " [0.07010779 0.90873539 0.02115693]\n",
      " [0.35465759 0.64188921 0.0034532 ]\n",
      " [0.5197528  0.4768053  0.00344188]]\n",
      "EVAL: [100/230] Loss: 0.7193(0.6210) \n",
      "[[2.12634983e-03 1.99112058e-01 7.98761606e-01]\n",
      " [5.25817974e-03 3.13603997e-01 6.81137860e-01]\n",
      " [2.25260179e-03 1.94340244e-01 8.03407192e-01]\n",
      " [1.03162217e-03 8.93026367e-02 9.09665704e-01]\n",
      " [1.13206217e-03 5.37978448e-02 9.45070028e-01]\n",
      " [6.13440573e-03 3.63570660e-01 6.30294919e-01]\n",
      " [6.15437049e-03 3.55635673e-01 6.38209939e-01]\n",
      " [5.20175381e-04 3.22053581e-02 9.67274427e-01]\n",
      " [9.33518342e-04 7.33654872e-02 9.25701022e-01]\n",
      " [2.67159194e-03 1.82292789e-01 8.15035582e-01]]\n",
      "EVAL: [150/230] Loss: 0.9133(0.6393) \n",
      "[[0.04191264 0.622545   0.33554235]\n",
      " [0.02878611 0.3489455  0.62226838]\n",
      " [0.03540806 0.4540104  0.51058149]\n",
      " [0.03954429 0.40943551 0.55102021]\n",
      " [0.23224391 0.72527069 0.04248533]\n",
      " [0.04543775 0.63598168 0.31858054]\n",
      " [0.02303459 0.41277781 0.56418765]\n",
      " [0.14715762 0.8053447  0.04749767]\n",
      " [0.03159534 0.38577044 0.58263421]\n",
      " [0.13241732 0.85622871 0.011354  ]]\n",
      "EVAL: [200/230] Loss: 0.5291(0.6497) \n",
      "[[7.32821599e-02 7.51957178e-01 1.74760610e-01]\n",
      " [6.96928725e-02 7.77801394e-01 1.52505770e-01]\n",
      " [4.90975864e-02 6.94487333e-01 2.56415188e-01]\n",
      " [2.43789420e-01 6.96043193e-01 6.01673648e-02]\n",
      " [1.24596234e-03 1.12683877e-01 8.86070192e-01]\n",
      " [5.12314998e-02 7.58429348e-01 1.90339133e-01]\n",
      " [4.12184000e-03 3.11844379e-01 6.84033811e-01]\n",
      " [6.35008141e-03 3.47978950e-01 6.45670950e-01]\n",
      " [1.17056653e-01 7.79054523e-01 1.03888892e-01]\n",
      " [6.67440414e-04 6.55539259e-02 9.33778644e-01]]\n",
      "EVAL: [229/230] Loss: 0.5985(0.6475) \n",
      "[[0.17082542 0.80408382 0.02509069]\n",
      " [0.53000951 0.46665812 0.00333242]\n",
      " [0.24300116 0.71932185 0.03767698]\n",
      " [0.04247812 0.91838723 0.03913466]\n",
      " [0.26293465 0.72835171 0.00871363]\n",
      " [0.1321339  0.76381791 0.10404818]\n",
      " [0.65769833 0.33994251 0.00235913]\n",
      " [0.10617425 0.87581968 0.01800603]\n",
      " [0.08657838 0.90928876 0.00413292]\n",
      " [0.33986661 0.65005308 0.0100803 ]]\n",
      "EVAL: [0/230] Loss: 0.6359(0.6359) \n",
      "[[0.00345801 0.25900638 0.7375356 ]\n",
      " [0.00337336 0.25469863 0.74192804]\n",
      " [0.00181217 0.14498857 0.85319924]\n",
      " [0.03393022 0.56548613 0.40058365]\n",
      " [0.00358112 0.24182013 0.75459874]\n",
      " [0.00197943 0.13678761 0.86123294]\n",
      " [0.00308138 0.21212511 0.78479356]\n",
      " [0.0180282  0.50109851 0.48087323]\n",
      " [0.00353613 0.31298572 0.68347818]\n",
      " [0.17416862 0.80053234 0.02529899]]\n",
      "EVAL: [50/230] Loss: 0.5180(0.6011) \n",
      "[[0.00170863 0.16370146 0.83458996]\n",
      " [0.18641169 0.57589889 0.23768939]\n",
      " [0.16938058 0.77802455 0.05259485]\n",
      " [0.07238952 0.84108001 0.08653055]\n",
      " [0.07977138 0.79394501 0.12628359]\n",
      " [0.05180831 0.65463412 0.29355755]\n",
      " [0.09297363 0.84836107 0.05866529]\n",
      " [0.0594675  0.55299836 0.38753417]\n",
      " [0.05110766 0.84364504 0.10524735]\n",
      " [0.21994877 0.69959581 0.08045545]]\n",
      "EVAL: [100/230] Loss: 0.7533(0.6268) \n",
      "[[0.25874996 0.73380077 0.00744927]\n",
      " [0.31287381 0.68265557 0.00447062]\n",
      " [0.70772141 0.28973591 0.00254268]\n",
      " [0.28676292 0.70621425 0.00702281]\n",
      " [0.20019537 0.79155815 0.00824645]\n",
      " [0.57740104 0.42127037 0.00132854]\n",
      " [0.0488709  0.93252504 0.01860413]\n",
      " [0.07460599 0.85207713 0.07331692]\n",
      " [0.09356122 0.87848479 0.02795398]\n",
      " [0.20814176 0.76976717 0.02209106]]\n",
      "EVAL: [150/230] Loss: 1.0202(0.6422) \n",
      "[[0.05710699 0.93320858 0.00968442]\n",
      " [0.04341838 0.91795951 0.03862206]\n",
      " [0.13481629 0.84277666 0.02240705]\n",
      " [0.0638512  0.90979564 0.02635311]\n",
      " [0.21189167 0.76917958 0.01892867]\n",
      " [0.04828847 0.91098237 0.04072919]\n",
      " [0.04983485 0.86942977 0.0807353 ]\n",
      " [0.05398578 0.89656055 0.04945371]\n",
      " [0.04365439 0.80761087 0.14873473]\n",
      " [0.42907625 0.54873312 0.02219059]]\n",
      "EVAL: [200/230] Loss: 0.7037(0.6403) \n",
      "[[0.2170524  0.78154415 0.00140344]\n",
      " [0.08676834 0.91073281 0.00249885]\n",
      " [0.33720022 0.66167033 0.0011294 ]\n",
      " [0.09219199 0.90508008 0.0027279 ]\n",
      " [0.32845548 0.67030948 0.00123506]\n",
      " [0.1178811  0.88020003 0.00191892]\n",
      " [0.50918829 0.489793   0.00101876]\n",
      " [0.2981205  0.70079112 0.00108838]\n",
      " [0.22276972 0.77601975 0.00121053]\n",
      " [0.11263386 0.88282949 0.00453662]]\n",
      "EVAL: [229/230] Loss: 0.3779(0.6345) \n",
      "[[0.00101828 0.0809616  0.91802013]\n",
      " [0.00331116 0.28860375 0.70808512]\n",
      " [0.00108983 0.08336764 0.91554254]\n",
      " [0.00182342 0.21944173 0.77873486]\n",
      " [0.44998693 0.54616094 0.00385211]\n",
      " [0.03777344 0.81342006 0.14880645]\n",
      " [0.14417072 0.84252357 0.01330569]\n",
      " [0.15460137 0.83457786 0.0108208 ]\n",
      " [0.14793675 0.78951085 0.06255243]\n",
      " [0.09943639 0.88044614 0.02011749]]\n",
      "EVAL: [0/230] Loss: 0.4075(0.4075) \n",
      "[[0.30586439 0.68961036 0.0045252 ]\n",
      " [0.10721576 0.87561178 0.01717245]\n",
      " [0.21389709 0.7797038  0.00639905]\n",
      " [0.08250766 0.90360034 0.01389205]\n",
      " [0.06248782 0.91763449 0.01987766]\n",
      " [0.01130561 0.51539654 0.47329786]\n",
      " [0.00218997 0.22643858 0.77137142]\n",
      " [0.00504547 0.33376846 0.6611861 ]\n",
      " [0.00303698 0.25603214 0.74093091]\n",
      " [0.00178666 0.19835421 0.79985911]]\n",
      "EVAL: [50/230] Loss: 0.5880(0.5974) \n",
      "[[0.07930917 0.46015742 0.46053338]\n",
      " [0.05940188 0.53342372 0.40717438]\n",
      " [0.16058038 0.70508242 0.13433723]\n",
      " [0.11790031 0.76404792 0.11805177]\n",
      " [0.07224509 0.83941865 0.08833617]\n",
      " [0.04428658 0.88585508 0.06985837]\n",
      " [0.20253226 0.76805675 0.02941099]\n",
      " [0.12236062 0.79560304 0.08203627]\n",
      " [0.36530754 0.62568432 0.00900811]\n",
      " [0.08662897 0.83140343 0.08196758]]\n",
      "EVAL: [100/230] Loss: 0.6161(0.5934) \n",
      "[[0.10256808 0.88999414 0.00743771]\n",
      " [0.1668382  0.82825506 0.00490669]\n",
      " [0.10188149 0.8836236  0.01449489]\n",
      " [0.1485059  0.84622002 0.00527407]\n",
      " [0.23638776 0.75805181 0.00556042]\n",
      " [0.140222   0.85575169 0.00402628]\n",
      " [0.25027031 0.72918051 0.02054918]\n",
      " [0.03411306 0.7952804  0.17060652]\n",
      " [0.03451524 0.63002425 0.33546048]\n",
      " [0.06036221 0.59102106 0.34861675]]\n",
      "EVAL: [150/230] Loss: 0.5226(0.6116) \n",
      "[[1.85762288e-03 1.53854445e-01 8.44287872e-01]\n",
      " [2.27114325e-03 1.73793375e-01 8.23935449e-01]\n",
      " [7.13920803e-04 5.00161014e-02 9.49270010e-01]\n",
      " [4.47072415e-03 2.86995888e-01 7.08533406e-01]\n",
      " [9.28566908e-04 5.81416078e-02 9.40929890e-01]\n",
      " [3.21814138e-03 2.21528828e-01 7.75252998e-01]\n",
      " [3.28862760e-03 1.81955725e-01 8.14755619e-01]\n",
      " [9.95718758e-04 8.09392631e-02 9.18065012e-01]\n",
      " [4.04256675e-03 3.17497402e-01 6.78460002e-01]\n",
      " [4.32224339e-03 3.10212076e-01 6.85465693e-01]]\n",
      "EVAL: [200/230] Loss: 0.4704(0.6249) \n",
      "[[2.95724813e-03 2.09877267e-01 7.87165523e-01]\n",
      " [9.65956540e-04 7.39636943e-02 9.25070345e-01]\n",
      " [6.19913975e-04 5.05298637e-02 9.48850214e-01]\n",
      " [7.56656984e-04 6.34693429e-02 9.35773969e-01]\n",
      " [6.96109375e-03 4.68125612e-01 5.24913311e-01]\n",
      " [3.72667164e-02 7.61276126e-01 2.01457143e-01]\n",
      " [7.25632459e-02 8.34969997e-01 9.24667418e-02]\n",
      " [6.28334060e-02 8.70328307e-01 6.68383241e-02]\n",
      " [1.42943844e-01 7.50706196e-01 1.06349945e-01]\n",
      " [3.08781385e-01 6.86700284e-01 4.51830775e-03]]\n",
      "EVAL: [229/230] Loss: 0.4741(0.6166) \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(test) > 1:\n",
    "    with timer(\"deberta_v3_large\"):\n",
    "        oof = np.zeros([len(train), 3])\n",
    "#         # dataset\n",
    "#         valid_datagen = FeedbackDataset(\n",
    "#             deberta_v3_large_tokenizer, \n",
    "#             test, \n",
    "#             max_len\n",
    "#         )\n",
    "\n",
    "#         # loader\n",
    "#         valid_generator = DataLoader(\n",
    "#             dataset=valid_datagen,\n",
    "#             batch_size=batch_size,\n",
    "#             shuffle=False,\n",
    "#             num_workers=2,\n",
    "#             pin_memory=True,\n",
    "#             drop_last=False\n",
    "#         )\n",
    "#         folds = [0,1,2,3,4]\n",
    "        for fold in range(5):\n",
    "            val_losses = AverageMeter()\n",
    "            valid_df = train.loc[train['fold'] == fold].reset_index(drop=True)\n",
    "            valid_datagen = FeedbackDataset(\n",
    "                deberta_v3_large_tokenizer, \n",
    "                valid_df, \n",
    "                max_len\n",
    "            )\n",
    "            valid_generator = DataLoader(\n",
    "                dataset=valid_datagen,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=4,\n",
    "                pin_memory=True,\n",
    "                drop_last=False\n",
    "            )\n",
    "\n",
    "            folds = [0,1,2,3,4]\n",
    "            # model\n",
    "            model = FeedbackModel(model_name = 'microsoft/deberta-v3-large', config_path = './config.pth', pretrained=False)\n",
    "            model.load_state_dict(torch.load(f\"../output/ex/ex001/ex001_model/ex001_{fold}.pth\"))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            preds = np.ndarray([0,3])\n",
    "\n",
    "            for step, (batch_input_ids, batch_attention_mask, batch_target) in enumerate(valid_generator):\n",
    "                batch_input_ids = batch_input_ids.to(device)\n",
    "                batch_attention_mask = batch_attention_mask.to(device)\n",
    "                batch_target = torch.from_numpy(np.array(batch_target)).float().to(device)\n",
    "                with torch.no_grad():\n",
    "                    logits = model(batch_input_ids, batch_attention_mask)\n",
    "                    loss = nn.CrossEntropyLoss()(logits, batch_target)\n",
    "                \n",
    "                val_losses.update(loss.item(), logits.size(0))\n",
    "                x = logits.to('cpu').numpy()\n",
    "                logits = softmax(logits.to('cpu').numpy())\n",
    "                preds = np.concatenate(\n",
    "                        [preds, logits], axis=0\n",
    "                    ) \n",
    "                if step % 50 == 0 or step == (len(valid_generator)-1):\n",
    "                    print(\n",
    "                        'EVAL: [{0}/{1}] '\n",
    "                        'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                        .format(\n",
    "                            step, \n",
    "                            len(valid_generator),\n",
    "                            loss=val_losses,\n",
    "                        )\n",
    "                    )\n",
    "            oof[fold_array == fold] = preds\n",
    "            del model,valid_datagen, valid_generator\n",
    "            gc.collect()\n",
    "\n",
    "        # y_test_deberta_v3_large = np.mean(y_test_deberta_v3_large,axis=0)\n",
    "        # del valid_datagen, valid_generator\n",
    "        # gc.collect()\n",
    "\n",
    "del deberta_v3_large_tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "818b1ffb-768c-497e-b8ca-67c4e125e98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(test) > 1:\n",
    "    with timer(\"deberta_v3_large\"):\n",
    "        y_test_deberta_v3_large = []\n",
    "        # dataset\n",
    "        valid_datagen = FeedbackDataset(\n",
    "            deberta_v3_large_tokenizer, \n",
    "            test, \n",
    "            max_len\n",
    "        )\n",
    "\n",
    "        # loader\n",
    "        valid_generator = DataLoader(\n",
    "            dataset=valid_datagen,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "        for fold in range(5):\n",
    "\n",
    "            # model\n",
    "            model = FeedbackModel(model_name = 'microsoft/deberta-v3-large', config_path = './config.pth', pretrained=False)\n",
    "            model.load_state_dict(torch.load(f\"../output/ex/ex001/ex001_model/ex001_{fold}.pth\"))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            test_preds = np.ndarray([0,3])\n",
    "\n",
    "            for step, (batch_input_ids, batch_attention_mask) in enumerate(valid_generator):\n",
    "                batch_input_ids = batch_input_ids.to(device)\n",
    "                batch_attention_mask = batch_attention_mask.to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    logits = model(batch_input_ids, batch_attention_mask)\n",
    "                logits = softmax(logits.to('cpu').numpy())\n",
    "                test_preds = np.concatenate(\n",
    "                        [test_preds, logits], axis=0\n",
    "                    )    \n",
    "            y_test_deberta_v3_large.append(test_preds)\n",
    "            del model\n",
    "            gc.collect()\n",
    "\n",
    "        y_test_deberta_v3_large = np.mean(y_test_deberta_v3_large,axis=0)\n",
    "        del valid_datagen, valid_generator\n",
    "        gc.collect()\n",
    "\n",
    "del deberta_v3_large_tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ac75984-9b45-49e0-aa3a-d9b0e2dd2674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01500432, 0.50554253, 0.47945313],\n",
       "       [0.0358187 , 0.87410471, 0.09007663],\n",
       "       [0.03873662, 0.81119816, 0.15006521],\n",
       "       [0.0523075 , 0.8237339 , 0.1239586 ],\n",
       "       [0.04561032, 0.80198406, 0.15240565],\n",
       "       [0.02685003, 0.52322471, 0.44992526],\n",
       "       [0.01977329, 0.43787841, 0.54234828],\n",
       "       [0.03587363, 0.77802705, 0.18609938],\n",
       "       [0.02197314, 0.42942826, 0.5485986 ],\n",
       "       [0.03117581, 0.71913257, 0.24969162]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_deberta_v3_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1050c9f2-70ea-431b-bdbf-0858a22c5894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36765,)\n",
      "oof_score:0.6341769603843165\n"
     ]
    }
   ],
   "source": [
    "# correct solution:\n",
    "def get_target(x):\n",
    "    target = np.array([0,0,0])\n",
    "    target[x] = 1\n",
    "    return target\n",
    "y = train['label'].values\n",
    "print(y.shape)\n",
    "val_score = log_loss(y, oof)\n",
    "print(f'oof_score:{val_score}')\n",
    "np.save('../output/ex/ex001/ex001_oof.npy', oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e234faaf-cdd4-411f-bf0c-4631ea60fb39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'oof' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moof\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'oof' is not defined"
     ]
    }
   ],
   "source": [
    "oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb885fcd-58ec-4921-b757-715796a4ad92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f8a00f-3c9e-4491-8aa5-bc202c4c9cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
